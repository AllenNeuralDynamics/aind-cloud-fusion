{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ca7060-4447-4a2a-8ecf-f16d65db5b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fsspec.mapping.get_mapper(url='', check=False, create=False, missing_exceptions=None, alternate_root=None, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fsspec\n",
    "import s3fs\n",
    "import zarr\n",
    "import time\n",
    "\n",
    "fsspec.get_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e782b238-6dac-4bd1-b801-115119e37dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from numcodecs import Blosc\n",
    "\n",
    "@dataclass\n",
    "class OutputParameters:\n",
    "    path: str\n",
    "    chunksize: tuple[int, int, int, int, int]\n",
    "    resolution_zyx: tuple[float, float, float]\n",
    "    dtype: np.dtype = np.uint16\n",
    "    dimension_separator: str = \"/\"\n",
    "    compressor = Blosc(cname='zstd', clevel=1, shuffle=Blosc.SHUFFLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd8c617-eb46-4dad-9fa5-1cb4fa0ee0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m      9\u001b[0m s3 \u001b[38;5;241m=\u001b[39m s3fs\u001b[38;5;241m.\u001b[39mS3FileSystem(\n\u001b[1;32m     10\u001b[0m     use_listings_cache\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     11\u001b[0m     config_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m store \u001b[38;5;241m=\u001b[39m s3fs\u001b[38;5;241m.\u001b[39mS3Map(root\u001b[38;5;241m=\u001b[39moutput_params\u001b[38;5;241m.\u001b[39mpath, s3\u001b[38;5;241m=\u001b[39ms3)\n\u001b[0;32m---> 24\u001b[0m out_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m chunksize \u001b[38;5;241m=\u001b[39m output_params\u001b[38;5;241m.\u001b[39mchunksize\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/zarr/hierarchy.py:1426\u001b[0m, in \u001b[0;36mgroup\u001b[0;34m(store, overwrite, chunk_store, cache_attrs, synchronizer, path, zarr_version, meta_array)\u001b[0m\n\u001b[1;32m   1424\u001b[0m requires_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zarr_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1426\u001b[0m     requires_init \u001b[38;5;241m=\u001b[39m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontains_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m zarr_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   1428\u001b[0m     requires_init \u001b[38;5;241m=\u001b[39m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contains_group(store, path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/zarr/storage.py:127\u001b[0m, in \u001b[0;36mcontains_group\u001b[0;34m(store, path, explicit_only)\u001b[0m\n\u001b[1;32m    125\u001b[0m store_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(store, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_store_version\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m explicit_only:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m store:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/zarr/storage.py:1478\u001b[0m, in \u001b[0;36mFSStore.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1477\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_key(key)\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/mapping.py:189\u001b[0m, in \u001b[0;36mFSMap.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Does key exist in mapping?\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_to_str(key)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39misfile(path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/asyn.py:91\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# this loops allows thread to get interrupted\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use active aind-open-data exapsim directory\n",
    "output_params = OutputParameters(\n",
    "    path='s3://aind-open-data/exaSPIM_674191_2023-09-12_12-37-37_full_res_2024-01-23_02-31-19/channel_561.zarr',\n",
    "    chunksize=(1, 1, 128, 128, 128),\n",
    "    resolution_zyx=(1.0, 0.748, 0.748),\n",
    ")\n",
    "output_volume_size = (28700, 19617, 14224)\n",
    "\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    use_listings_cache= True, \n",
    "    config_kwargs={\n",
    "        'max_pool_connections': 50,\n",
    "        's3': {\n",
    "          'multipart_threshold': 64 * 1024 * 1024,  # 64 MB, avoid multipart upload for small chunks\n",
    "          'max_concurrent_requests': 20  # Increased from 10 -> 20.\n",
    "        },\n",
    "        'retries': {\n",
    "          'total_max_attempts': 100,\n",
    "          'mode': 'adaptive',\n",
    "        }\n",
    "    }\n",
    ")\n",
    "store = s3fs.S3Map(root=output_params.path, s3=s3)\n",
    "out_group = zarr.group(store=store, overwrite=True)   # This is the problem line\n",
    "path = \"0\"\n",
    "chunksize = output_params.chunksize\n",
    "datatype = output_params.dtype\n",
    "dimension_separator = \"/\"\n",
    "compressor = output_params.compressor\n",
    "output_volume_1 = out_group.create_dataset(\n",
    "    path,\n",
    "    shape=(\n",
    "        1,\n",
    "        1,\n",
    "        output_volume_size[0],\n",
    "        output_volume_size[1],\n",
    "        output_volume_size[2],\n",
    "    ),\n",
    "    chunks=chunksize,\n",
    "    dtype=datatype,\n",
    "    compressor=compressor,\n",
    "    dimension_separator=dimension_separator,\n",
    "    overwrite=True,\n",
    "    fill_value=0,\n",
    ")\n",
    "\n",
    "output_slice = (\n",
    "    slice(0, 1),\n",
    "    slice(0, 1),\n",
    "    slice(0, 300),\n",
    "    slice(0, 300),\n",
    "    slice(0, 300),\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "output_volume_1[output_slice] = np.zeros((1, 1, 300, 300, 300))\n",
    "print(f'Time: {time.time() - start_time}')\n",
    "\n",
    "# Interesting\n",
    "# latency appears to be related to re-initalizing the output dataset. \n",
    "# Maybe there is another way to init this connection object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54383109-50e2-4e4d-94e3-ffbcd1550038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 8.466339111328125\n"
     ]
    }
   ],
   "source": [
    "# Let's see if zarr.open works\n",
    "\n",
    "out_vol = zarr.open_group('s3://aind-open-data/exaSPIM_674191_2023-09-12_12-37-37_full_res_2024-01-23_02-31-19/channel_561.zarr', mode='a')\n",
    "\n",
    "output_slice = (\n",
    "    slice(0, 1),\n",
    "    slice(0, 1),\n",
    "    slice(0, 300),\n",
    "    slice(0, 300),\n",
    "    slice(0, 300),\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "out_vol[output_slice] = np.zeros((1, 1, 300, 300, 300))\n",
    "print(f'Time: {time.time() - start_time}')\n",
    "\n",
    "# Got it, \n",
    "# There is an API call to create a zarr array and another api call to open/access one\n",
    "# Not like a typical database connection. \n",
    "\n",
    "# The change: \n",
    "# - Scheduler makes the group at the s3 path (create_output_store)\n",
    "# - Workers connect to group given s3 path in OutputParameters (connect_to_output_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8813df-9a78-4e09-9f33-3d8609c2987a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, can default to zarr.open and check for this error: \n",
    "\n",
    "zarr.hierarchy.contains_group(store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33544194-f192-4a39-bc91-0a6e9c97fb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_params = OutputParameters(\n",
    "    path='s3://aind-scratch-data/jonathan.wong/test_2.zarr',\n",
    "    chunksize=(1, 1, 128, 128, 128),\n",
    "    resolution_zyx=(1.0, 0.748, 0.748),\n",
    ")\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    use_listings_cache= False, \n",
    "    config_kwargs={\n",
    "        'max_pool_connections': 50,\n",
    "        's3': {\n",
    "          'multipart_threshold': 64 * 1024 * 1024,  # 64 MB, avoid multipart upload for small chunks\n",
    "          'max_concurrent_requests': 20  # Increased from 10 -> 20.\n",
    "        },\n",
    "        'retries': {\n",
    "          'total_max_attempts': 100,\n",
    "          'mode': 'adaptive',\n",
    "        }\n",
    "    }\n",
    ")\n",
    "store = s3fs.S3Map(root=output_params.path, s3=s3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eca3ade-c9a4-4e64-bf4a-cb2524f5d398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 5.0344603061676025\n"
     ]
    }
   ],
   "source": [
    "# Init new aind-test-data exapsim directory\n",
    "output_params = OutputParameters(\n",
    "    path='s3://aind-scratch-data/jonathan.wong/exaSPIM_674191_2023-09-12_12-37-37_full_res_2024-01-23_02-31-19/channel_561.zarr',\n",
    "    chunksize=(1, 1, 128, 128, 128),\n",
    "    resolution_zyx=(1.0, 0.748, 0.748),\n",
    ")\n",
    "output_volume_size = (28700, 19617, 14224)\n",
    "\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    use_listings_cache= False, \n",
    "    config_kwargs={\n",
    "        'max_pool_connections': 50,\n",
    "        's3': {\n",
    "          'multipart_threshold': 64 * 1024 * 1024,  # 64 MB, avoid multipart upload for small chunks\n",
    "          'max_concurrent_requests': 20  # Increased from 10 -> 20.\n",
    "        },\n",
    "        'retries': {\n",
    "          'total_max_attempts': 100,\n",
    "          'mode': 'adaptive',\n",
    "        }\n",
    "    }\n",
    ")\n",
    "store = s3fs.S3Map(root=output_params.path, s3=s3)\n",
    "out_group = zarr.open_group(store=store, mode='a')\n",
    "path = \"0\"\n",
    "chunksize = output_params.chunksize\n",
    "datatype = output_params.dtype\n",
    "dimension_separator = \"/\"\n",
    "compressor = output_params.compressor\n",
    "output_volume_2 = out_group.create_dataset(\n",
    "    path,\n",
    "    shape=(\n",
    "        1,\n",
    "        1,\n",
    "        output_volume_size[0],\n",
    "        output_volume_size[1],\n",
    "        output_volume_size[2],\n",
    "    ),\n",
    "    chunks=chunksize,\n",
    "    dtype=datatype,\n",
    "    compressor=compressor,\n",
    "    dimension_separator=dimension_separator,\n",
    "    overwrite=True,\n",
    "    fill_value=0,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "output_volume_2[output_slice] = np.zeros((1, 1, 300, 300, 300))\n",
    "print(f'Time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b513e2-ab1b-46fb-99d6-8eb32791a3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
